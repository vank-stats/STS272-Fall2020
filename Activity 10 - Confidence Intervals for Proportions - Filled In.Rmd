---
title: "Activity 10 - Confidence Intervals for Proportions"
author: "STS272 (Dr. VanKrevelen)"
date: 'Updated: 9/20/2020'
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE}
library(ggplot2)
library(infer)
library(dplyr)
```

For this example, we'll look at a study where researchers trained a dog to smell COVID-19 virus. You can read more about it (and watch a video) [here](https://nerdist.com/article/dogs-sniff-out-covid/).

```{r, out.width = '75%', fig.align = 'center', echo = FALSE, fig.cap = 'Sniffer dog at work'}
knitr::include_graphics('https://nerdist.com/wp-content/uploads/2020/07/C19-sniffing-dogs-feature-image-07272020.jpg')
```

# Part 1 - A single proportion

1. I've created a dataset out of the data in the article. You can see it below. How many observations are there? What are the variables and what does each one mean?

```{r}
covid_dog <- data.frame(ID = c(rep("positive", 157), rep("negative", 792),
                               rep("positive", 33), rep("negative", 30)),
                        actual = c(rep("positive", 157), rep("negative", 792),
                                   rep("negative", 33), rep("positive", 30))) %>%
  mutate(correct = factor(ID == actual))
```

- There are 1,012 observations
- The variables are `ID` (what the dog picked), `actual` (whether the specimen actually contained COVID-19), and `correct` (whether the dog got it right)

<br>

2. Let's start by just looking at cases where the sample was actually positive for COVID-19. You can use the `filter()` function to select only rows where `actual == "positive"`. Store this in a new object.

```{r}
covid_dog_pos <- filter(covid_dog, actual == "positive")
```

<br>

3. What proportion of positive tests did the dog correctly identify? How can we calculate this in R?

```{r}
covid_dog_pos %>%
  specify(formula = correct ~ NULL, success = "TRUE") %>%
  calculate(stat = "prop")
```

84% of positive specimens were correctly identified. This is our sample proportion ($\hat{p}$)

4. This was just one sample. What we're really interested in is how well this dog would do in the long run. What is our parameter of interest?

p = population proportion of positive specimens the dog can correctly identify

<br>

5. Generate a bootstrap distribution of sample proportions from 1,000 samples. Create a histogram of your 1,000 sample proportions from this distribution. Since we're going to be using randomization, let's set a seed here so that we can reproduce our results in the future.

```{r}
set.seed(57974)
covid_dog_boot <- covid_dog_pos %>%
  specify(formula = correct ~ NULL, success = "TRUE") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "prop")
visualize(covid_dog_boot)
```

<br>

6. Create a 95% confidence interval using the method of your choice. Write the interval below.

```{r}
get_confidence_interval(covid_dog_boot, level = 0.95, type = "percentile")
```

Our interval is (0.781, 0.893)

<br>

7. Provide a sentence interpreting your interval in context of this example.

We are 95% confident that this dog can correctly identify between 78.1% and 89.3% of specimens where COVID-19 is present.

<br>

8. Suppose we wanted a narrower interval than the one we got. How could we achieve that?

One way would be to collect a bigger sample. This would mean that our point estimate would be a better guess for the parameter, so we wouldn't need as big of a "net" to catch the parameter.

If we were unable to collect a bigger sample, we could reduce our level of confidence (say to 90% or 80%). We wouldn't be as confident the parameter was in our interval, but we would have a narrower range to present.

---

# Part 2- Comparing proportions

9. Now let's consider whether the dog does a better job identifying positive or negative specimens. Before we get started, let's make a graph comparing the two. Fill in the blanks below to create this graph. Try running the graph with and without `position = fill` to see what that argument does. (Note: Remove `eval = FALSE` to run your code)

```{r}
ggplot(covid_dog) +
  geom_bar(aes(x = actual, fill = correct), position = "fill")
```


<br>

10. What does the graph show? What does `position = fill` do and why might we want to include it here?

It looks like the dog does better identifying negative specimens than positive ones. However, this is just one sample, so we should investigate what kind of sampling variability there would be from sample to sample.

The `position = FILL` argument makes it so the bars have the same height. This lets us compare proportions (since the number of positive and negative specimens wasn't the same).

<br>

11. Clearly the dog didn't do equally well with positive and negative cases in our sample, but we want to apply this to a population. What is our parameter of interest? Put it in context of this problem.

$p_1 - p_2$ = the population proportion of correct guesses the dog makes on negative specimens minus the population proportion of correct guesses it makes on positive specimens

<br>

12. Let's calculate our point estimate. We can use the `infer` package to do this and just skip the `generate()` step. (Note: Remove `eval = FALSE` to run your code)

```{r}
dog_pointest <- covid_dog %>%
  specify(formula = correct ~ actual, success = "TRUE") %>%
  calculate(stat = "diff in props", order = c("negative", "positive"))
dog_pointest
```

<br>

13. Now we need to generate a bootstrap distribution to better understand how this estimate might vary from sample to sample. You can copy and paste your code from above but change `dog_pointest` to a new name and add a `generate()` line in between `specify()` and `calculate()`. Make a histogram of your sample proportions from this distribution.

```{r}
dog_boot_diff <- covid_dog %>%
  specify(formula = correct ~ actual, success = "TRUE") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "diff in props", order = c("negative", "positive"))
visualize(dog_boot_diff)
```

<br>

14. Generate a 95% confidence interval based on this bootstrap distribution.

```{r}
get_confidence_interval(dog_boot_diff, level = 0.95, type = "se", 
                        point_estimate = dog_pointest)
```

Our interval goes from (0.068, 0.173). This is the interval that I believe my difference in population proportions falls into (using negative - positive). Because the interval is entirely positive, I believe the dog is better at correctly IDing negative specimens.

<br>

15. Interpret the interval in context of the problem. Consider writing the sentence so that it could be included in the article linked at the top of the page and be understood by someone reading that article.

I am 95% confident that the dog will correctly identify negative specimens between 6.8 and 17.3 percentage points more often than it will correctly identify positive specimens.